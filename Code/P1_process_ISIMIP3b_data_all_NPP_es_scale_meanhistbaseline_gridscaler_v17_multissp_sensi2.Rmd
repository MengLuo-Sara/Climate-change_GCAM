---
title: "process_ISIMIP3b_data"
author: "Meng"
date: "2024-03-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r S0 set path and install package}
# require(devtools)
#Please use this in console if needed: install_github('JGCRI/rgcam', build_vignettes=TRUE, force =TRUE)


library(tidyverse)
library(tidyr)
library(dplyr)
library(patchwork)
library(sf)
library(svglite)
library(cowplot)
library(gridExtra)
library(ggthemes)
library(scales) # for the percentage format on y-axis
library(RColorBrewer)


library(ncdf4)
library(raster)
library(ggplot2)
library(viridis)


library(purrr)



# chen lab desktop
# root <- "O:/"

# 2023 laptop
root <- "D:/"

fig_save_path <- paste0(root,"E/new laptop2/PHD/my_2024_1_manuscript/Figure&table/figure/")


## C:\MengLuo\E\new laptop2\PHD\ISIMIP 3b

in_ISIMIP3b_main_path <- paste0(root,"E/new laptop2/ISIMIP data/ISIMIP_3b/")
out_main_path<-paste0(root,"E/new laptop2/PHD/phd_dissertation/climate_FPC_GCAM/Data/ISIMIP3b_processed/GCAM_subregion_mean/")
baseline_path<-paste0(root,"E/new laptop2/PHD/phd_dissertation/climate_FPC_GCAM/Data/ISIMIP3b_processed/baseline rh npp/baseline/")


gcam_subregion_mapping <- read.csv(paste0(root,"E/new laptop2/PHD/phd_dissertation/climate_FPC_GCAM/Code/R/GCAM_mapping/gcam2glm_mapping.csv"))
# read shp file
# shp_path <- paste0(root, "E/new laptop2/PHD/GCAM/boundary/gcam_boundaries_moirai_3p1_0p5arcmin_wgs84/gcam_boundaries_moirai_3p1_0p5arcmin_wgs84/main_outputs/region_boundaries_moirai_combined_3p1_0p5arcmin.shp")
# # plot(data_sf)
# data_sf <- st_read(shp_path)

```

```{r S1 functions}
##########################################################################
# Function to process each layer
process_layer <- function(data_slice, year_label, lon_min, lon_max, lat_min, lat_max) {
  raster_layer <- raster(t(data_slice), xmn=lon_min, xmx=lon_max, ymn=lat_min, ymx=lat_max, crs=CRS("+proj=longlat +datum=WGS84"))
  ISIMIP_matrix <- as.data.frame(rasterToPoints(raster_layer)) %>%
    rename(lon = x, lat = y, value = layer) %>%
    filter(value < 10e20) %>%
    mutate(year_label = year_label)
  
  return(ISIMIP_matrix)
}


#############################################################################
# Function to process each year
process_year_pft_npp <- function(year, data1, data2) {
  
  #################
  ## test
  # year<-years1[1]
  # data1 <-ISIMIP_gcam_pft
  # data2 <-ISIMIP_gcam_npp_pft
  # 

  ################
  # Calculate the total for each group in data1
  data1_2 <- data1 %>%
    filter(year_label == year) %>%
    group_by(out_reg_code, out_lu_code, gcam_reg_name, basin_abr) %>%
    summarise(pft_total = sum(pft * weight * cos(center_lat*pi/180), na.rm = TRUE), .groups = 'drop')

  # Join this back to data2 and calculate the new pft values
  result <- data2 %>%
    filter(year_label == year) %>%
    dplyr::select(-center_lon) %>%  # Exclude 'center_lon' from data2 before joining
    left_join(data1_2, by = c("out_reg_code", "out_lu_code", "gcam_reg_name", "basin_abr")) %>%
    mutate(pft_new = (pft * weight * cos(center_lat*pi/180)) / pft_total) %>%
    mutate(pft_new = ifelse(is.na(pft_new), 0, pft_new)) %>%
    dplyr::select(-weight, -pft, -pft_total, -center_lat) %>%  # Exclude specific columns after calculations
    group_by(out_reg_code, out_lu_code, gcam_reg_name, basin_abr) %>%
    summarise(npp_mean = weighted.mean(npp, pft_new, na.rm = TRUE), .groups = 'drop')

  return(result)
}





# # Function to process each year
# process_year_npp <- function(year, data) {
#   data %>%
#     filter(year_label == year) %>%
#     group_by(out_reg_code,out_lu_code,gcam_reg_name,basin_abr) %>%
#     summarise(agg_lu_value = weighted.mean(npp, pft_weight), .groups = 'drop')
# }

##########################################################################
# Function to dynamically rename and join data frames
join_and_rename_pft_npp <- function(data_list, join_keys) {
  result_df <- data_list[[1]] %>% 
    rename(!!paste0("npp_mean", 2015) := npp_mean)
  
  if (length(data_list) > 1) {
    for (i in 2:length(data_list)) {
      year <- 2014 + i  # Adjust based on your actual year naming needs
      column_name <- paste0("npp_mean", year)
      
      # Dynamically rename and join
      result_df <- result_df %>% 
        left_join(data_list[[i]] %>% 
                    rename(!!column_name := npp_mean),
                  by = join_keys)
    }
  }
  
  return(result_df)
}



##########################################################################
# Function to process each layer with weighting
process_layer_with_weighting <- function(data_slices, year_label, lon_min, lon_max, lat_min, lat_max, month_weights) {
  weighted_data_slices <- list()
  for (m in 1:length(data_slices)) {
    # Apply the monthly weight to each data slice
    weighted_data_slices[[m]] <- data_slices[[m]] * month_weights[m]
  }
  # Sum the weighted data slices to get the annual weighted average
  annual_data_slice <- Reduce("+", weighted_data_slices)
  
  raster_layer <- raster(t(annual_data_slice), xmn=lon_min, xmx=lon_max, ymn=lat_min, ymx=lat_max, crs=CRS("+proj=longlat +datum=WGS84"))
  ISIMIP_matrix <- as.data.frame(rasterToPoints(raster_layer)) %>%
    rename(lon = x, lat = y, value = layer) %>%
    filter(value < 10e20) %>%
    mutate(year_label = year_label)
  
  return(ISIMIP_matrix)
}
```

```{r S2 automatically read the nc file}

# Specify the directory containing the .nc files

# ## SSP585
npp_dir_path <- paste0(root, "E/new laptop2/ISIMIP data/ISIMIP_3b/npp ssp585 w5e5 all_sensitivity_type")
pft_dir_path <- paste0(root, "E/new laptop2/ISIMIP data/ISIMIP_3b/pft ssp585 w5e5 all_sensitivity_type")
# ## SSP126
# npp_dir_path <- paste0(root, "E/new laptop2/ISIMIP data/ISIMIP_3b/npp ssp126 w5e5 all_sensitivity_type")
# pft_dir_path <- paste0(root, "E/new laptop2/ISIMIP data/ISIMIP_3b/pft ssp126 w5e5 all_sensitivity_type")
## SSP370
# npp_dir_path <- paste0(root, "E/new laptop2/ISIMIP data/ISIMIP_3b/npp ssp370 w5e5 all_sensitivity_type")
# pft_dir_path <- paste0(root, "E/new laptop2/ISIMIP data/ISIMIP_3b/pft ssp370 w5e5 all_sensitivity_type")





# List all .nc files in the directory
## only ssp585 have nondep

havenondep <- 0

if (havenondep == 1) {

######################################################################################################################

npp_files <- list.files(path = npp_dir_path, pattern = "2015soc-from-histsoc.*_nondep.*\\.nc$", full.names = TRUE)
pft_files <- list.files(path = pft_dir_path, pattern = "2015soc-from-histsoc.*_nondep.*\\.nc$", full.names = TRUE)



} else {
######################################################################################################################
# all do not include nondep
# Step 1: Get all files including "2015soc-from-histsoc"
initial_npp_files <- list.files(path = npp_dir_path, pattern = "2015soc-from-histsoc.*\\.nc$", full.names = TRUE)
initial_pft_files <- list.files(path = pft_dir_path, pattern = "2015soc-from-histsoc.*\\.nc$", full.names = TRUE)

# Step 2: Exclude files containing "_nondep"
npp_files <- initial_npp_files[!grepl("_nondep", initial_npp_files)]
pft_files <- initial_pft_files[!grepl("_nondep", initial_pft_files)]

}

print(npp_files)
print(pft_files)

```

```{r S3 read data}
## read in nc file

lon_min <- -180
lon_max <- 180
lat_min <- -90
lat_max <- 90


# check<-npp_dcdcldbdltr[,,1]
###############################

month_weight<-c(31,28,31,30,31,30,31,31,30,31,30,31)/365


################



```


```{r S4 process agb, bgb to gcam subregion weight mean at gridded level}
# for(data_idx in 1:length(npp_files)) {
# 46:54
for(data_idx in c(1:9,19:27)) {
  # data_idx <- 46
  # Record the start time
  start_time <- Sys.time()
  
  
  in_npp <- npp_files[data_idx]
  in_pft <- pft_files[data_idx]
  
  ncfile_npp <- nc_open(in_npp)
  ncfile_pft <- nc_open(in_pft)
  
  # Extract the PFT part from the file name using a regular expression
  pft_part <- sub(".*_pft-(.*?)_.*", "\\1", basename(in_pft))
  
  pft_pft <- paste0("pft-", pft_part)
  npp_pft <- paste0("npp-", pft_part)
  
  # get variable from nc
  npp_dcdcldbdltr <- ncvar_get(ncfile_npp, npp_pft)
  pft_dcdcldbdltr <- ncvar_get(ncfile_pft, pft_pft)
  
  # Close the NetCDF file
  nc_close(ncfile_npp)
  nc_close(ncfile_pft)
  
  ###########################
  # Extract the file name from the path
  npp_file_name <- basename(in_npp)
  
  # Use a regular expression to remove the trailing part of the file name, starting from "_global"
  # This will keep the part of the file name before "_global"
  desired_name_part <- sub("_global.*", "", npp_file_name)
  model_name <- sub("_w5e5.*", "", npp_file_name)
  
  
  pattern <- "npp-(.*?)_global"
  match <-
    regmatches(npp_file_name, regexpr(pattern, npp_file_name, perl = TRUE))
  pft_name <- gsub("npp-(.*?)_global", "\\1", match)
  
  
  # Print the extracted part to check
  # print(desired_name_part)
  
  
  ######################################################################
  ######################################################################
  ## read the baseline data
  if (havenondep == 1) {
    baseline <-
      read.csv(
        paste0(
          baseline_path,
          model_name,
          "_w5e5_historical_histsoc_nondep_npp-",
          pft_name,
          "_rh_npp_baseline.csv"
        )
      )
    
    
  }  else{
    baseline <-
      read.csv(
        paste0(
          baseline_path,
          model_name,
          "_w5e5_historical_histsoc_default_npp-",
          pft_name,
          "_rh_npp_baseline.csv"
        )
      )
    
    
    
  }
  
  ## end ## read the baseline data
  ######################################################################
  ######################################################################
  
  
  # Initialize an empty data frame for the results
  all_ISIMIP_matrices_npp0 <- data.frame()
  all_ISIMIP_matrices_pft <- data.frame()
  
  
  ##################################################################
  ##################################################################
  # extract aggregate monthly to annually
  # Assuming each 12 consecutive layers represent one year
  num_years <- 1032 / 12
  for (year_idx in 1:num_years) {
    #year_idx<-1
    # Extract slices for the current year
    start_layer <- (year_idx - 1) * 12 + 1
    end_layer <- year_idx * 12
    data_slices <-
      lapply(start_layer:end_layer, function(i)
        npp_dcdcldbdltr[, , i])
    
    year_label <-
      paste0(2015 + (year_idx - 1)) # Adjust based on your actual year labeling needs
    
    # print(year_label)
    
    ISIMIP_matrix_npp <-
      process_layer_with_weighting(data_slices,
                                   year_label,
                                   lon_min,
                                   lon_max,
                                   lat_min,
                                   lat_max,
                                   month_weight)
    
    all_ISIMIP_matrices_npp0 <-
      bind_rows(all_ISIMIP_matrices_npp0, ISIMIP_matrix_npp)
  }
  
  
  
  
  
  # the npp baseline here is the npp data in 2015
  all_ISIMIP_matrices_npp <- all_ISIMIP_matrices_npp0 %>%
    pivot_wider(values_from = value, names_from = year_label)
  
  # Apply a function over rows (MARGIN=1) that checks if any values from the 10th column to the last are below 0
  rows_to_remove <-
    apply(all_ISIMIP_matrices_npp[, 3:ncol(all_ISIMIP_matrices_npp)], 1, function(x)
      any(x < 0))
  
  # Filter out the rows where the condition is TRUE
  # all_ISIMIP_matrices_npp_filtered <-
  #   all_ISIMIP_matrices_npp[!rows_to_remove, ] %>%
  #   pivot_longer(
  #     cols = 3:ncol(all_ISIMIP_matrices_npp),
  #     values_to = "value" ,
  #     names_to = "year_label"
  #   )
  
  
   all_ISIMIP_matrices_npp_filtered <-
    all_ISIMIP_matrices_npp[!rows_to_remove, ] %>%
    pivot_longer(
      cols = all_of(3:ncol(all_ISIMIP_matrices_npp)),
      values_to = "value" ,
      names_to = "year_label"
    )
  
  
  
  
  
  ## make sure npp data has all lon lat row, and has all year for each pair of lon lat
  all_ISIMIP_matrices_npp2 <- gcam_subregion_mapping %>%
    dplyr::select(center_lat, center_lon) %>%
    tidyr::expand_grid(year_label = 2015:2100, .) %>%
    mutate(year_label = as.character(year_label)) %>%
    arrange(center_lat, center_lon, year_label) %>%
    left_join(
      all_ISIMIP_matrices_npp_filtered,
      by = c(
        "center_lon" = "lon",
        "center_lat" = "lat",
        "year_label"
      )
    ) %>%
    dplyr::select(center_lat, center_lon, year_label, value) %>%
    ## newly added
    distinct()
  
 
  baseline2 <- baseline %>%
    rename(value = npp) %>%
    dplyr::select(c("center_lon", "center_lat", "year_label", "value")) %>%
    pivot_wider(values_from = value, names_from = year_label)
  #######################################################################################
  
  df<-all_ISIMIP_matrices_npp2
  ## check data by ploting
  selected_year <- 2020
df_selected <- df[df$year_label == selected_year, ]

# Convert data frame to sf object
df_sf <- sf::st_as_sf(df_selected, coords = c("center_lon", "center_lat"), crs = 4326)

ggplot(data = df_sf) +
  geom_sf(aes(size = value, color = value), alpha = 0.6) +
  scale_color_viridis_c() +
  ggtitle(paste("Spatial Distribution of Values for the Year", selected_year)) +
  theme_minimal() +
  labs(color = "Value", size = "Value") +
  theme(legend.position = "right")

    #######################################################################################
  ## estimate the scaler: npp/npp baseline
  all_ISIMIP_matrices_npp <-
    all_ISIMIP_matrices_npp2 %>%
    pivot_wider(values_from = value, names_from = year_label) %>%
    left_join(baseline2, by = c("center_lon", "center_lat")) %>%
    pivot_longer(cols = 3:89,
                 names_to = "year_label",
                 values_to = "value") %>%
    arrange(center_lat, center_lon, year_label)
  
  
  
  all_ISIMIP_matrices_npp3 <-
    all_ISIMIP_matrices_npp %>% group_by(center_lon, center_lat) %>%
    mutate(value = value / value[year_label == "2014"]) %>%
    ungroup()
  
  #######################################################################################
  #######################################################################################
  
  ## add the min (0.125) and max (2) limit
  all_ISIMIP_matrices_npp4 <- all_ISIMIP_matrices_npp3 %>%
    mutate(value = ifelse(value > 2, 2, value)) %>%
    mutate(value = ifelse(value < 0.125, 0.125, value))
  
  #######################################################################################
  #######################################################################################
  # PFT Loop through each time dimension for annualy data
  for (i in 1:86) {
    data_slice_pft <- pft_dcdcldbdltr[, , i]
    year_label_pft <-
      paste0(2015 + (i - 1)) # Adjust based on your actual year labeling needs
    ISIMIP_matrix_pft <-
      process_layer(data_slice_pft,
                    year_label_pft,
                    lon_min,
                    lon_max,
                    lat_min,
                    lat_max)
    all_ISIMIP_matrices_pft <-
      bind_rows(all_ISIMIP_matrices_pft, ISIMIP_matrix_pft)
  }
  
  
  
  
  
  #######################################################################################
  
  
  # Assuming gcam_subregion_mapping and all_ISIMIP_matrices are ready for joining
  ISIMIP_gcam_npp_pft <- gcam_subregion_mapping %>%
    left_join(all_ISIMIP_matrices_npp4 %>% rename (npp = value),
              by = c("center_lon" , "center_lat")) %>%
    distinct()%>%
    left_join(
      all_ISIMIP_matrices_pft %>%
        ## newly added
        distinct() %>% rename (pft = value),
      by = c(
        "center_lon" = "lon",
        "center_lat" = "lat",
        "year_label"
      )
    ) %>%
    ## newly added
    distinct()
  
 
  # save proceed data
  write.csv(
    ISIMIP_gcam_npp_pft,
    paste0(
      out_main_path,
      "/annual_wmean_aboveCD/grid/",
      desired_name_part,
      "_grid_annualy_scale.csv"
    ),
    row.names = FALSE
  )
  
  
  
  # Record the end time
  end_time <- Sys.time()
  
  # Calculate the duration and print it
  duration <- end_time - start_time
  print(duration)
  
}


```

```{r S5 check npp_rh}

check_aboveCD_long <- ISIMIP_gcam_combined_pft_npp%>%
  pivot_longer(
    cols = starts_with("npp_mean"),
    names_to = "year",
    values_to = "value",
    names_prefix = "npp_mean"
  )%>%
  mutate(year = as.numeric(year))%>%
  na.omit()

  # Create a line plot for each region
p<-ggplot(check_aboveCD_long, aes(x = as.numeric(year), y = value, group = basin_abr, color = basin_abr)) +
  geom_line() +
  labs(title = "Line Plot of Each Region Over Years",
       x = "Year",
       y = "Value",
       color = "Region") +
  theme_minimal()

## save 

# Save the plot as an SVG file
ggsave(paste0(fig_save_path,"/",desired_name_part,"_aCD.svg"), plot = p, width = 20, height = 20, units = "in")


####################################################################


check_aboveCD_long_mean <- ISIMIP_gcam_combined_pft_npp%>%
dplyr::select(5:ncol(.)) %>%  
  summarise_all(~ mean(., na.rm = TRUE))%>%
  pivot_longer(
    cols = starts_with("npp_mean"),
    names_to = "year",
    values_to = "value",
    names_prefix = "npp_mean"
  )%>%
  mutate(year = as.numeric(year))%>%
  na.omit()


p2<-ggplot(check_aboveCD_long_mean, aes(x = as.numeric(year), y = value)) +
  geom_line() +
  labs(title = "Line Plot of Each Region Over Years",
       x = "Year",
       y = "Value") +
  theme_minimal()

## save 

# Save the plot as an SVG file
ggsave(paste0(fig_save_path,"/",desired_name_part,"_aCD_mean.svg"), plot = p2, width = 20, height = 20, units = "in")

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
